{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.collocations import *\n",
    "#from nltk import FreqDist, word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Activation, LSTM, GRU, Dense, GlobalMaxPool1D, Embedding, Dropout, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/drug_review_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Etonogestrel'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_conditions[top_10_conditions.index=='Birth Control'].drugName.value_counts()[:1].keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_conditions = drugs.set_index('condition').loc[drugs.condition.value_counts()[:10].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_10_conditions.groupby(top_10_conditions.index)['drugName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_drug_for_condition = []\n",
    "for i in top_10_conditions.index.unique():\n",
    "    drug_name = top_10_conditions[top_10_conditions.index==i].drugName.value_counts()[:1].keys()[0]\n",
    "    top_drug_for_condition.append(drug_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Etonogestrel',\n",
       " 'Bupropion',\n",
       " 'Tramadol',\n",
       " 'Escitalopram',\n",
       " 'Isotretinoin',\n",
       " 'Lamotrigine',\n",
       " 'Zolpidem',\n",
       " 'Phentermine',\n",
       " 'Bupropion / naltrexone',\n",
       " 'Lisdexamfetamine']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_drug_for_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_drugs = pd.DataFrame()\n",
    "for i in top_drug_for_condition:\n",
    "    top_drugs = pd.concat([top_drugs, top_10_conditions[top_10_conditions.drugName==i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_tokenization(text, num_words=3000):\n",
    "    tokenizer = Tokenizer(num_words)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer.texts_to_matrix(text, mode='binary')\n",
    "\n",
    "def hot_pad_sequences(text, num_words=3000, maxlen=100):    \n",
    "    tokenizer = Tokenizer(num_words)\n",
    "    tokenizer.fit_on_texts(list(text))\n",
    "    list_tokenized_headlines = tokenizer.texts_to_sequences(text)\n",
    "    return sequence.pad_sequences(list_tokenized_headlines, maxlen) \n",
    "\n",
    "def hot_label_encoding(labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    labels_cat = le.transform(labels)\n",
    "    return to_categorical(labels_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = hot_tokenization(top_drugs.lemm_review, 3000)\n",
    "y = hot_label_encoding(top_drugs.drugName)\n",
    "train, test, label_train, label_test = train_test_split(X_t, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = hot_pad_sequences(top_drugs.lemm_review, 3000, maxlen=100)\n",
    "y = hot_label_encoding(top_drugs.drugName)\n",
    "train, test, label_train, label_test = train_test_split(X_t, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(3000,)))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9332 samples, validate on 1037 samples\n",
      "Epoch 1/20\n",
      "9332/9332 [==============================] - 1s 143us/step - loss: 0.6209 - acc: 0.8542 - val_loss: 0.6526 - val_acc: 0.8351\n",
      "Epoch 2/20\n",
      "9332/9332 [==============================] - 1s 152us/step - loss: 0.6070 - acc: 0.8586 - val_loss: 0.6394 - val_acc: 0.8447\n",
      "Epoch 3/20\n",
      "9332/9332 [==============================] - 1s 153us/step - loss: 0.5936 - acc: 0.8623 - val_loss: 0.6267 - val_acc: 0.8476\n",
      "Epoch 4/20\n",
      "9332/9332 [==============================] - 1s 142us/step - loss: 0.5806 - acc: 0.8671 - val_loss: 0.6143 - val_acc: 0.8534\n",
      "Epoch 5/20\n",
      "9332/9332 [==============================] - 1s 153us/step - loss: 0.5680 - acc: 0.8693 - val_loss: 0.6021 - val_acc: 0.8554\n",
      "Epoch 6/20\n",
      "9332/9332 [==============================] - 1s 153us/step - loss: 0.5558 - acc: 0.8724 - val_loss: 0.5903 - val_acc: 0.8621\n",
      "Epoch 7/20\n",
      "9332/9332 [==============================] - 1s 147us/step - loss: 0.5440 - acc: 0.8755 - val_loss: 0.5795 - val_acc: 0.8660\n",
      "Epoch 8/20\n",
      "9332/9332 [==============================] - 1s 155us/step - loss: 0.5326 - acc: 0.8797 - val_loss: 0.5691 - val_acc: 0.8669\n",
      "Epoch 9/20\n",
      "9332/9332 [==============================] - 2s 166us/step - loss: 0.5215 - acc: 0.8830 - val_loss: 0.5580 - val_acc: 0.8708\n",
      "Epoch 10/20\n",
      "9332/9332 [==============================] - 1s 155us/step - loss: 0.5108 - acc: 0.8844 - val_loss: 0.5481 - val_acc: 0.8756\n",
      "Epoch 11/20\n",
      "9332/9332 [==============================] - 1s 150us/step - loss: 0.5005 - acc: 0.8874 - val_loss: 0.5390 - val_acc: 0.8785\n",
      "Epoch 12/20\n",
      "9332/9332 [==============================] - 2s 161us/step - loss: 0.4905 - acc: 0.8897 - val_loss: 0.5294 - val_acc: 0.8824\n",
      "Epoch 13/20\n",
      "9332/9332 [==============================] - 1s 158us/step - loss: 0.4808 - acc: 0.8919 - val_loss: 0.5201 - val_acc: 0.8843\n",
      "Epoch 14/20\n",
      "9332/9332 [==============================] - 1s 150us/step - loss: 0.4714 - acc: 0.8932 - val_loss: 0.5119 - val_acc: 0.8891\n",
      "Epoch 15/20\n",
      "9332/9332 [==============================] - 2s 165us/step - loss: 0.4624 - acc: 0.8962 - val_loss: 0.5033 - val_acc: 0.8891\n",
      "Epoch 16/20\n",
      "9332/9332 [==============================] - 2s 165us/step - loss: 0.4536 - acc: 0.8970 - val_loss: 0.4956 - val_acc: 0.8891\n",
      "Epoch 17/20\n",
      "9332/9332 [==============================] - 2s 161us/step - loss: 0.4452 - acc: 0.8970 - val_loss: 0.4879 - val_acc: 0.8910\n",
      "Epoch 18/20\n",
      "9332/9332 [==============================] - 1s 150us/step - loss: 0.4370 - acc: 0.8986 - val_loss: 0.4797 - val_acc: 0.8910\n",
      "Epoch 19/20\n",
      "9332/9332 [==============================] - 1s 159us/step - loss: 0.4291 - acc: 0.9011 - val_loss: 0.4733 - val_acc: 0.8930\n",
      "Epoch 20/20\n",
      "9332/9332 [==============================] - 1s 158us/step - loss: 0.4214 - acc: 0.9015 - val_loss: 0.4657 - val_acc: 0.8910\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, label_train, epochs=20, batch_size=256, validation_split=0.1)\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = hot_pad_sequences(top_drugs.lemm_review, 3000, maxlen=100)\n",
    "y = hot_label_encoding(top_drugs.drugName)\n",
    "train, test, label_train, label_test = train_test_split(X_t, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 80)           240000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 99, 60)            9660      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 251,800\n",
      "Trainable params: 251,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(3000, 80, input_length=100))\n",
    "model.add(Conv1D(60, 2, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9332 samples, validate on 1037 samples\n",
      "Epoch 1/6\n",
      "9332/9332 [==============================] - 26s 3ms/step - loss: 1.6500 - acc: 0.4273 - val_loss: 1.0436 - val_acc: 0.6731\n",
      "Epoch 2/6\n",
      "9332/9332 [==============================] - 24s 3ms/step - loss: 0.6759 - acc: 0.7991 - val_loss: 0.4071 - val_acc: 0.8737\n",
      "Epoch 3/6\n",
      "9332/9332 [==============================] - 26s 3ms/step - loss: 0.3680 - acc: 0.8871 - val_loss: 0.3079 - val_acc: 0.8949\n",
      "Epoch 4/6\n",
      "9332/9332 [==============================] - 30s 3ms/step - loss: 0.2746 - acc: 0.9189 - val_loss: 0.2876 - val_acc: 0.9026\n",
      "Epoch 5/6\n",
      "9332/9332 [==============================] - 32s 3ms/step - loss: 0.2143 - acc: 0.9359 - val_loss: 0.2865 - val_acc: 0.9055\n",
      "Epoch 6/6\n",
      "9332/9332 [==============================] - 33s 4ms/step - loss: 0.1696 - acc: 0.9495 - val_loss: 0.2866 - val_acc: 0.9065\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, label_train, epochs=6, validation_split=0.1, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Etonogestrel                          4394\n",
       "Ethinyl estradiol / norethindrone     3081\n",
       "Levonorgestrel                        2884\n",
       "Nexplanon                             2883\n",
       "Ethinyl estradiol / levonorgestrel    2107\n",
       "Ethinyl estradiol / norgestimate      2097\n",
       "Implanon                              1496\n",
       "Mirena                                1320\n",
       "Skyla                                 1074\n",
       "Lo Loestrin Fe                         896\n",
       "Name: drugName, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs[drugs.condition=='Birth Control'].drugName.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_birthcontrol_drugs = drugs.set_index('drugName').loc[drugs[drugs.condition=='Birth Control'].drugName.value_counts()[:10].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = hot_tokenization(top_birthcontrol_drugs.lemm_review, 3000)\n",
    "y = hot_label_encoding(top_birthcontrol_drugs.index)\n",
    "train, test, label_train, label_test = train_test_split(X_t, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(3000,)))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18763 samples, validate on 2085 samples\n",
      "Epoch 1/40\n",
      "18763/18763 [==============================] - 5s 284us/step - loss: 2.2966 - acc: 0.1367 - val_loss: 2.2754 - val_acc: 0.1923\n",
      "Epoch 2/40\n",
      "18763/18763 [==============================] - 3s 156us/step - loss: 2.2524 - acc: 0.2220 - val_loss: 2.2380 - val_acc: 0.2331\n",
      "Epoch 3/40\n",
      "18763/18763 [==============================] - 3s 145us/step - loss: 2.2134 - acc: 0.2533 - val_loss: 2.2023 - val_acc: 0.2513\n",
      "Epoch 4/40\n",
      "18763/18763 [==============================] - 3s 143us/step - loss: 2.1740 - acc: 0.2727 - val_loss: 2.1646 - val_acc: 0.2667\n",
      "Epoch 5/40\n",
      "18763/18763 [==============================] - 3s 149us/step - loss: 2.1316 - acc: 0.2897 - val_loss: 2.1227 - val_acc: 0.2758\n",
      "Epoch 6/40\n",
      "18763/18763 [==============================] - 3s 145us/step - loss: 2.0850 - acc: 0.2968 - val_loss: 2.0769 - val_acc: 0.2873\n",
      "Epoch 7/40\n",
      "18763/18763 [==============================] - 3s 150us/step - loss: 2.0354 - acc: 0.3074 - val_loss: 2.0276 - val_acc: 0.3017\n",
      "Epoch 8/40\n",
      "18763/18763 [==============================] - 3s 148us/step - loss: 1.9836 - acc: 0.3256 - val_loss: 1.9762 - val_acc: 0.3199\n",
      "Epoch 9/40\n",
      "18763/18763 [==============================] - 3s 148us/step - loss: 1.9305 - acc: 0.3465 - val_loss: 1.9233 - val_acc: 0.3501\n",
      "Epoch 10/40\n",
      "18763/18763 [==============================] - 3s 150us/step - loss: 1.8760 - acc: 0.3748 - val_loss: 1.8688 - val_acc: 0.3722\n",
      "Epoch 11/40\n",
      "18763/18763 [==============================] - 3s 155us/step - loss: 1.8198 - acc: 0.3996 - val_loss: 1.8125 - val_acc: 0.3957\n",
      "Epoch 12/40\n",
      "18763/18763 [==============================] - 3s 152us/step - loss: 1.7619 - acc: 0.4194 - val_loss: 1.7547 - val_acc: 0.4067\n",
      "Epoch 13/40\n",
      "18763/18763 [==============================] - 3s 159us/step - loss: 1.7021 - acc: 0.4359 - val_loss: 1.6949 - val_acc: 0.4216\n",
      "Epoch 14/40\n",
      "18763/18763 [==============================] - 3s 158us/step - loss: 1.6419 - acc: 0.4459 - val_loss: 1.6358 - val_acc: 0.4326\n",
      "Epoch 15/40\n",
      "18763/18763 [==============================] - 3s 164us/step - loss: 1.5835 - acc: 0.4533 - val_loss: 1.5798 - val_acc: 0.4403\n",
      "Epoch 16/40\n",
      "18763/18763 [==============================] - 3s 164us/step - loss: 1.5285 - acc: 0.4625 - val_loss: 1.5277 - val_acc: 0.4427\n",
      "Epoch 17/40\n",
      "18763/18763 [==============================] - 3s 169us/step - loss: 1.4779 - acc: 0.4676 - val_loss: 1.4802 - val_acc: 0.4552\n",
      "Epoch 18/40\n",
      "18763/18763 [==============================] - 3s 169us/step - loss: 1.4320 - acc: 0.4737 - val_loss: 1.4373 - val_acc: 0.4600\n",
      "Epoch 19/40\n",
      "18763/18763 [==============================] - 3s 184us/step - loss: 1.3909 - acc: 0.4807 - val_loss: 1.4003 - val_acc: 0.4633\n",
      "Epoch 20/40\n",
      "18763/18763 [==============================] - 3s 167us/step - loss: 1.3543 - acc: 0.4852 - val_loss: 1.3666 - val_acc: 0.4657\n",
      "Epoch 21/40\n",
      "18763/18763 [==============================] - 4s 187us/step - loss: 1.3217 - acc: 0.4904 - val_loss: 1.3361 - val_acc: 0.4691\n",
      "Epoch 22/40\n",
      "18763/18763 [==============================] - 3s 186us/step - loss: 1.2925 - acc: 0.4935 - val_loss: 1.3096 - val_acc: 0.4705\n",
      "Epoch 23/40\n",
      "18763/18763 [==============================] - 3s 178us/step - loss: 1.2664 - acc: 0.5002 - val_loss: 1.2854 - val_acc: 0.4739\n",
      "Epoch 24/40\n",
      "18763/18763 [==============================] - 4s 218us/step - loss: 1.2429 - acc: 0.5041 - val_loss: 1.2641 - val_acc: 0.4705\n",
      "Epoch 25/40\n",
      "18763/18763 [==============================] - 4s 238us/step - loss: 1.2218 - acc: 0.5069 - val_loss: 1.2449 - val_acc: 0.4782\n",
      "Epoch 26/40\n",
      "18763/18763 [==============================] - 4s 233us/step - loss: 1.2025 - acc: 0.5096 - val_loss: 1.2273 - val_acc: 0.4801\n",
      "Epoch 27/40\n",
      "18763/18763 [==============================] - 5s 241us/step - loss: 1.1849 - acc: 0.5122 - val_loss: 1.2117 - val_acc: 0.4820\n",
      "Epoch 28/40\n",
      "18763/18763 [==============================] - 5s 244us/step - loss: 1.1688 - acc: 0.5147 - val_loss: 1.1973 - val_acc: 0.4820\n",
      "Epoch 29/40\n",
      "18763/18763 [==============================] - 5s 250us/step - loss: 1.1537 - acc: 0.5177 - val_loss: 1.1848 - val_acc: 0.4882\n",
      "Epoch 30/40\n",
      "18763/18763 [==============================] - 4s 214us/step - loss: 1.1403 - acc: 0.5193 - val_loss: 1.1724 - val_acc: 0.4906\n",
      "Epoch 31/40\n",
      "18763/18763 [==============================] - 4s 223us/step - loss: 1.1276 - acc: 0.5229 - val_loss: 1.1619 - val_acc: 0.4882\n",
      "Epoch 32/40\n",
      "18763/18763 [==============================] - 4s 214us/step - loss: 1.1158 - acc: 0.5223 - val_loss: 1.1517 - val_acc: 0.4916\n",
      "Epoch 33/40\n",
      "18763/18763 [==============================] - 4s 226us/step - loss: 1.1049 - acc: 0.5270 - val_loss: 1.1429 - val_acc: 0.4940\n",
      "Epoch 34/40\n",
      "18763/18763 [==============================] - 5s 273us/step - loss: 1.0946 - acc: 0.5284 - val_loss: 1.1348 - val_acc: 0.4916\n",
      "Epoch 35/40\n",
      "18763/18763 [==============================] - 6s 315us/step - loss: 1.0850 - acc: 0.5325 - val_loss: 1.1255 - val_acc: 0.4930\n",
      "Epoch 36/40\n",
      "18763/18763 [==============================] - 4s 193us/step - loss: 1.0757 - acc: 0.5342 - val_loss: 1.1192 - val_acc: 0.4926\n",
      "Epoch 37/40\n",
      "18763/18763 [==============================] - 5s 268us/step - loss: 1.0675 - acc: 0.5350 - val_loss: 1.1126 - val_acc: 0.4916\n",
      "Epoch 38/40\n",
      "18763/18763 [==============================] - 8s 408us/step - loss: 1.0592 - acc: 0.5373 - val_loss: 1.1076 - val_acc: 0.4892\n",
      "Epoch 39/40\n",
      "18763/18763 [==============================] - 16s 875us/step - loss: 1.0520 - acc: 0.5401 - val_loss: 1.0997 - val_acc: 0.4916\n",
      "Epoch 40/40\n",
      "18763/18763 [==============================] - 16s 847us/step - loss: 1.0445 - acc: 0.5422 - val_loss: 1.0943 - val_acc: 0.4950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, label_train, epochs=40, batch_size=256, validation_split=0.1)\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = hot_pad_sequences(top_birthcontrol_drugs.lemm_review, 3000, maxlen=100)\n",
    "y = hot_label_encoding(top_birthcontrol_drugs.index)\n",
    "train, test, label_train, label_test = train_test_split(X_t, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 80)           240000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 99, 60)            9660      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 251,800\n",
      "Trainable params: 251,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(3000, 80, input_length=100))\n",
    "model.add(Conv1D(60, 2, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18763 samples, validate on 2085 samples\n",
      "Epoch 1/6\n",
      "18763/18763 [==============================] - 42s 2ms/step - loss: 1.8294 - acc: 0.3283 - val_loss: 1.2565 - val_acc: 0.4830\n",
      "Epoch 2/6\n",
      "18763/18763 [==============================] - 55s 3ms/step - loss: 1.2582 - acc: 0.4799 - val_loss: 1.0526 - val_acc: 0.5314\n",
      "Epoch 3/6\n",
      "18763/18763 [==============================] - 43s 2ms/step - loss: 1.0885 - acc: 0.5352 - val_loss: 0.9845 - val_acc: 0.5444\n",
      "Epoch 4/6\n",
      "18763/18763 [==============================] - 40s 2ms/step - loss: 1.0138 - acc: 0.5567 - val_loss: 0.9642 - val_acc: 0.5525\n",
      "Epoch 5/6\n",
      "18763/18763 [==============================] - 54s 3ms/step - loss: 0.9688 - acc: 0.5661 - val_loss: 0.9561 - val_acc: 0.5511\n",
      "Epoch 6/6\n",
      "18763/18763 [==============================] - 89s 5ms/step - loss: 0.9322 - acc: 0.5751 - val_loss: 0.9448 - val_acc: 0.5549\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, label_train, epochs=6, validation_split=0.1, batch_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_pad_sequences(text, num_words=2, maxlen=10):    \n",
    "    tokenizer = Tokenizer(num_words)\n",
    "    tokenizer.fit_on_texts(list(text))\n",
    "    list_tokenized_headlines = tokenizer.texts_to_sequences(text)\n",
    "    return sequence.pad_sequences(list_tokenized_headlines, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_pad_sequences(['sean','bill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
